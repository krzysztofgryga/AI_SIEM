# Storage Layer

**Warstwa Przechowywania** - Perzystencja danych i analiza anomalii.

## üìã Opis

Storage Layer odpowiada za:
- Przechowywanie event√≥w AI (zapytania, odpowiedzi, metryki)
- Wykrywanie anomalii (koszty, latencja, bezpiecze≈Ñstwo)
- Agregacjƒô metryk
- Generowanie raport√≥w

## üéØ Komponenty

### `EventStorage`
G≈Ç√≥wny komponent do przechowywania danych:
- SQLite database
- Indeksowane zapytania
- CRUD operations dla event√≥w i anomalii

### `AnomalyDetector`
Wykrywanie anomalii:
- Threshold-based detection
- Spike detection (3x ≈õrednia)
- Pattern analysis
- Security violation detection

## üöÄ Instalacja

```bash
cd components/storage-layer
pip install -r requirements.txt
```

## üí° U≈ºycie

### Event Storage

```python
from storage import EventStorage
from shared.models import AIEvent, EventType, Provider

# Inicjalizacja
storage = EventStorage(db_path="ai_monitoring.db")

# Zapisz event
event = AIEvent(
    event_type=EventType.RESPONSE,
    provider=Provider.OPENAI,
    model="gpt-3.5-turbo",
    prompt="Hello",
    response="Hi there!",
    latency_ms=450,
    cost_usd=0.0001,
    success=True
)
storage.store_event(event)

# Pobierz ostatnie eventy
recent = storage.get_recent_events(limit=10)

# Statystyki
stats = storage.get_statistics(hours=24)
print(f"Total requests: {stats['total_requests']}")
print(f"Success rate: {stats['success_rate']:.1%}")
print(f"Total cost: ${stats['total_cost_usd']:.4f}")
```

### Anomaly Detection

```python
from analyzer import AnomalyDetector

# Inicjalizacja z konfiguracjƒÖ
detector = AnomalyDetector(config={
    'cost_threshold_usd': 0.5,       # Alert gdy koszt > $0.50
    'latency_threshold_ms': 5000,    # Alert gdy latencja > 5s
    'error_rate_threshold': 0.1,     # Alert gdy b≈Çƒôdy > 10%
    'token_threshold': 8000,         # Alert gdy tokeny > 8000
    'spike_multiplier': 3.0          # Alert gdy 3x wy≈ºsze ni≈º ≈õrednia
})

# Analiza pojedynczego eventu
anomalies = detector.analyze_event(event, recent_events)

for anomaly in anomalies:
    print(f"‚ö†Ô∏è {anomaly.anomaly_type}: {anomaly.description}")
    if anomaly.severity in ['critical', 'high']:
        print(f"üö® Action: {anomaly.recommended_action}")

# Analiza wzorc√≥w
pattern_anomalies = detector.analyze_patterns(
    events=storage.get_recent_events(100),
    window_minutes=60
)
```

## üìä Wykrywane Anomalie

### Event-Level Anomalies

| Typ | Threshold | Severity | Opis |
|-----|-----------|----------|------|
| `high_cost` | > $0.50 | HIGH | Pojedyncze zapytanie jest kosztowne |
| `high_latency` | > 5000ms | MEDIUM | D≈Çugi czas odpowiedzi |
| `high_token_usage` | > 8000 | MEDIUM | Du≈ºo token√≥w w zapytaniu |
| `request_failure` | - | HIGH | B≈ÇƒÖd API |
| `prompt_injection` | - | CRITICAL | Wykryto pr√≥bƒô injection |
| `pii_detected` | - | HIGH | Dane osobowe w promptcie |

### Pattern-Level Anomalies

| Typ | Threshold | Severity | Opis |
|-----|-----------|----------|------|
| `cost_spike` | 3x avg | HIGH | Nag≈Çy wzrost koszt√≥w |
| `latency_spike` | 3x avg | MEDIUM | Nag≈Çy wzrost latencji |
| `high_error_rate` | > 10% | CRITICAL | Wysoki wska≈∫nik b≈Çƒôd√≥w |
| `model_errors` | > 5 w 10min | HIGH | Problemy z konkretnym modelem |
| `high_request_rate` | > 50/min | MEDIUM | Nietypowa liczba zapyta≈Ñ |
| `high_cost_rate` | > $10/h | HIGH | Wysokie koszty w czasie |

## üóÑÔ∏è Schema Bazy Danych

### Tabela `events`
```sql
CREATE TABLE events (
    id TEXT PRIMARY KEY,
    timestamp TEXT,
    event_type TEXT,
    provider TEXT,
    model TEXT,
    prompt TEXT,
    response TEXT,
    latency_ms REAL,
    tokens_prompt INTEGER,
    tokens_completion INTEGER,
    tokens_total INTEGER,
    cost_usd REAL,
    success BOOLEAN,
    error_message TEXT,
    risk_level TEXT,
    has_pii BOOLEAN,
    has_injection BOOLEAN,
    user_id TEXT,
    session_id TEXT
)
```

### Tabela `anomalies`
```sql
CREATE TABLE anomalies (
    id TEXT PRIMARY KEY,
    timestamp TEXT,
    event_id TEXT,
    anomaly_type TEXT,
    severity TEXT,
    description TEXT,
    recommended_action TEXT,
    metadata TEXT
)
```

## üìà Przyk≈Çadowe Zapytania

### Top Costly Requests
```python
events = storage.get_events_by_cost(
    min_cost=0.01,
    limit=10
)
```

### Events with PII
```python
pii_events = storage.get_events_with_pii(
    hours=24
)
```

### High Risk Events
```python
risky = storage.get_high_risk_events(
    hours=24,
    min_risk_level="high"
)
```

## üîí Data Retention

```python
from storage import EventStorage

storage = EventStorage()

# Usu≈Ñ stare eventy (starsze ni≈º 30 dni)
deleted_count = storage.cleanup_old_events(days=30)

# Archiwizuj do JSON
storage.archive_events(
    output_file="archive_2025_01.json",
    start_date="2025-01-01",
    end_date="2025-01-31"
)
```

## üîó Zale≈ºno≈õci

### Wej≈õcie (od)
- Collection Layer - eventy do zapisania
- Processing Layer (opcjonalne) - metryki przetwarzania

### Wyj≈õcie (do)
- Tools (CLI) - dane do wy≈õwietlenia
- Dashboards (przysz≈Ço≈õƒá) - metryki i wykresy

### Wsp√≥≈Çdzielone
- Shared models - AIEvent, Anomaly

## üìñ Wiƒôcej Informacji

- [Tools (CLI)](../../tools/README.md) - Narzƒôdzia CLI do przeglƒÖdania danych
- [G≈Ç√≥wny README](../../README.md) - PrzeglƒÖd systemu
