# üèóÔ∏è AI SIEM - Architektura 3-Warstwowa

## üìã Spis Tre≈õci

1. [PrzeglƒÖd Architektury](#przeglƒÖd-architektury)
2. [Warstwa Aplikacji (Application Layer)](#warstwa-aplikacji-application-layer)
3. [Warstwa Kolekcji (Collection Layer - MPC Server)](#warstwa-kolekcji-collection-layer---mpc-server)
4. [Warstwa Przetwarzania (Processing Layer)](#warstwa-przetwarzania-processing-layer)
5. [Kontrakt JSON-RPC](#kontrakt-json-rpc)
6. [Bezpiecze≈Ñstwo i PII Handling](#bezpiecze≈Ñstwo-i-pii-handling)
7. [Inteligentny Routing](#inteligentny-routing)
8. [Przyk≈Çady U≈ºycia](#przyk≈Çady-u≈ºycia)

---

## PrzeglƒÖd Architektury

AI SIEM wykorzystuje architekturƒô 3-warstwowƒÖ zaprojektowanƒÖ dla:
- **Skalowalno≈õci** - ka≈ºda warstwa mo≈ºe byƒá skalowana niezale≈ºnie
- **Bezpiecze≈Ñstwa** - MPC Server dzia≈Ça jak "airlock" filtrujƒÖc i kontrolujƒÖc dane
- **Elastyczno≈õci** - ≈Çatwa wymiana modeli i backend√≥w bez wp≈Çywu na aplikacje

```mermaid
flowchart TB
    subgraph Application["üéØ Application Layer (Clients)"]
        App1[Web App]
        App2[Mobile App]
        App3[Service/API]
        App4[CLI Tool]
    end

    subgraph Collection["üîí Collection Layer (MPC Server)"]
        MPC[MPC Server]

        subgraph MPCComponents["MPC Components"]
            Validator[Request Validator]
            Auth[Authentication]
            PII[PII Detection]
            Router[Intelligent Router]
            Audit[Audit Logger]
        end
    end

    subgraph Processing["‚öôÔ∏è Processing Layer"]
        subgraph Backends["Processing Backends"]
            LLM_Large[LLM Large<br/>GPT-4, Claude Opus]
            LLM_Small[LLM Small<br/>Local Models]
            Rules[Rule Engine<br/>Regex, Classifiers]
            Hybrid[Hybrid<br/>Rules + LLM]
        end
    end

    App1 & App2 & App3 & App4 --> MPC
    MPC --> Validator --> Auth --> PII --> Router --> Audit
    Router --> LLM_Large & LLM_Small & Rules & Hybrid

    style Application fill:#e1f5ff
    style Collection fill:#fff3e0
    style Processing fill:#e8f5e9
```

### Podzia≈Ç Odpowiedzialno≈õci

| Warstwa | Odpowiedzialno≈õƒá | Nie Robi |
|---------|-----------------|-----------|
| **Application** | Zbiera kontekst, buduje prompty, wysy≈Ça zapytania | Nie przetwarza danych, nie wykonuje analizy |
| **Collection (MPC)** | Normalizuje, waliduje, routuje, autoryzuje, audytuje | Nie przetwarza tre≈õci, tylko kontroluje przep≈Çyw |
| **Processing** | Wykonuje faktyczne przetwarzanie, analizy, scoring | Nie decyduje o routingu, nie zarzƒÖdza dostƒôpem |

---

## Warstwa Aplikacji (Application Layer)

### Opis

Warstwa aplikacji to **osobny klient / osobna us≈Çuga / osobny endpoint LLM**, kt√≥ry:
- Zbiera kontekst u≈ºytkownika
- Buduje prompty i zapytania
- Generuje ≈ºƒÖdania do MPC Server
- **NIE** wykonuje przetwarzania danych

### Komponenty

```
application/
‚îú‚îÄ‚îÄ client.py          # MPCClient - g≈Ç√≥wny klient
‚îú‚îÄ‚îÄ example_usage.py   # Przyk≈Çady u≈ºycia
‚îî‚îÄ‚îÄ __init__.py
```

### MPCClient - G≈Ç√≥wny Klient

```python
from application.client import MPCClient
from schemas.contracts import SensitivityLevel, ProcessingHint

client = MPCClient(
    application_id="my-app",
    auth_token="your-token",
    environment="prod"
)

# Wys≈Çanie zapytania
result = await client.process(
    prompt="Analyze this security log",
    sensitivity=SensitivityLevel.INTERNAL,
    processing_hint=ProcessingHint.AUTO
)

print(result['response'])
```

### SimpleMPCClient - Uproszczony Klient

```python
from application.client import SimpleMPCClient

client = SimpleMPCClient(auth_token="token")

# Proste zapytanie
response = await client.ask("What is API security?")

# Zapytanie z PII
response = await client.ask_secure(
    "My email is user@example.com",
    contains_pii=True
)
```

### Kluczowe Funkcje

1. **Budowanie Kontraktu** - konwertuje zapytania u≈ºytkownika na MPCRequest
2. **Komunikacja** - wysy≈Ça zapytania do MPC Server (HTTP/gRPC)
3. **Obs≈Çuga Odpowiedzi** - parsuje MPCResponse i zwraca wyniki
4. **Error Handling** - obs≈Çuguje b≈Çƒôdy i retry

---

## Warstwa Kolekcji (Collection Layer - MPC Server)

### Opis

**MPC (Multi-Provider Coordinator) Server** pe≈Çni rolƒô po≈õrednika komunikacyjnego, kt√≥ry:
- Odbiera dane z Application Layer
- Normalizuje i waliduje zapytania
- Kontroluje przep≈Çyw danych
- Pilnuje autoryzacji i polityki dostƒôpu
- Routuje do odpowiednich backend√≥w
- **NIE** przetwarza danych, tylko koordynuje i kolekcjonuje

### Komponenty

```
mpc_server/
‚îú‚îÄ‚îÄ server.py          # G≈Ç√≥wny serwer MPC
‚îú‚îÄ‚îÄ router.py          # Inteligentny system routingu
‚îî‚îÄ‚îÄ __init__.py
```

### Pipeline Przetwarzania

```mermaid
sequenceDiagram
    participant App as Application
    participant MPC as MPC Server
    participant Auth as Auth/Authz
    participant PII as PII Detector
    participant Router as Router
    participant Backend as Processing Backend

    App->>MPC: MPCRequest
    MPC->>MPC: Validate Schema
    MPC->>Auth: Authenticate Token
    Auth-->>MPC: Principal
    MPC->>Auth: Authorize Action
    Auth-->>MPC: Authorized/Denied

    alt Not Authorized
        MPC-->>App: Error: Authorization Failed
    end

    MPC->>PII: Detect PII
    PII-->>MPC: PII Result

    alt PII Detected + Wrong Backend
        MPC-->>App: Error: PII Routing Blocked
    end

    MPC->>Router: Route Request
    Router-->>MPC: Backend Decision
    MPC->>Backend: Forward Request
    Backend-->>MPC: Result
    MPC->>MPC: Audit Log
    MPC-->>App: MPCResponse
```

### Funkcje MPC Server

#### 1. Walidacja Schematu

```python
# Waliduje payload zgodnie z zarejestrowanym schematem
validated_payload = validate_payload(
    request.payload_schema,  # "llm.request.v1"
    request.payload
)
```

#### 2. Uwierzytelnianie i Autoryzacja

```python
# JWT token verification
principal = access_control.authenticate(request.auth.token)

# RBAC/ABAC authorization
is_authorized, reason = access_control.authorize(
    principal,
    action="process",
    resource_attributes={
        'sensitivity': request.config.sensitivity,
        'estimated_cost': 0.01
    }
)
```

#### 3. Wykrywanie PII

```python
# Detekcja PII w promptach
pii_result = pii_detector.detect(prompt_text)

if pii_result.has_pii:
    # Blokuj lub routuj do bezpiecznego backendu
    should_block, reason = pii_router.should_block(
        prompt_text,
        target_backend
    )
```

#### 4. Inteligentny Routing

```python
# Wyb√≥r odpowiedniego backendu
routing_decision = router.route(
    capability=CapabilityType.TEXT_GENERATION,
    sensitivity=SensitivityLevel.INTERNAL,
    processing_hint=ProcessingHint.AUTO,
    max_cost=1.0,
    max_latency_ms=5000,
    use_cascade=True
)
```

#### 5. Audit Logging

```python
# Logowanie wszystkich operacji (bez PII!)
audit.log_request(
    request_id=request_id,
    client_id=hash(client_id),  # Zahashowane
    action="process",
    sensitivity=sensitivity,
    outcome=Outcome.SUCCESS
)
```

---

## Warstwa Przetwarzania (Processing Layer)

### Opis

Warstwa przetwarzania to miejsce, gdzie odbywa siƒô **faktyczne przetwarzanie danych**:
- Scoring i analizy
- Inferencje na modelach
- Routing do system√≥w
- Klasyczne algorytmy (regex, regu≈Çy)

### Komponenty

```
processing/
‚îú‚îÄ‚îÄ backends.py        # Implementacje backend√≥w
‚îú‚îÄ‚îÄ __init__.py
‚îî‚îÄ‚îÄ (istniejƒÖce: analyzer.py, processor.py)
```

### Typy Backend√≥w

#### 1. LLM Backends

```python
# OpenAI
backend = OpenAIBackend(
    backend_id="openai:gpt-4",
    api_key=api_key,
    model="gpt-4"
)

# Ollama (local)
backend = OllamaBackend(
    backend_id="ollama:llama2",
    base_url="http://localhost:11434",
    model="llama2"
)
```

#### 2. Rule-Based Backends

```python
# Deterministyczne regu≈Çy
backend = RuleBasedBackend(
    backend_id="rules:classifier"
)

# Szybkie, tanie, przewidywalne
result = await backend.process("Error: timeout")
# Result: "Classification: ERROR_LOG"
```

#### 3. Hybrid Backends

```python
# Kombinacja: regu≈Çy ‚Üí LLM (je≈õli confidence < threshold)
hybrid = HybridBackend(
    backend_id="hybrid:rule-llm",
    rule_backend=RuleBasedBackend(),
    llm_backend=OllamaBackend(),
    confidence_threshold=0.8
)

# Pr√≥buje najpierw regu≈Ç (szybko/tanio)
# Je≈õli confidence < 0.8 ‚Üí fallback do LLM
```

### Backend Registry

```python
from processing.backends import get_backend_registry, initialize_default_backends

# Inicjalizacja
initialize_default_backends(
    openai_api_key=os.getenv("OPENAI_API_KEY"),
    ollama_url="http://localhost:11434"
)

# U≈ºycie
registry = get_backend_registry()
backend = registry.get("openai:gpt-3.5-turbo")

result = await backend.process(
    prompt="Analyze this",
    params={"temperature": 0.7}
)
```

---

## Kontrakt JSON-RPC

### Podstawowa Zasada Kontraktu

‚úÖ **Schema-first** - wszystkie zapytania/odpowiedzi zgodne ze schematem
‚úÖ **Wersjonowanie** - `mpc_version`, `payload_schema`
‚úÖ **Stateless** - ka≈ºde zapytanie kompletne i samoopisowe
‚úÖ **Idempotentno≈õƒá** - `request_id`, `idempotency_key`

### Request Schema

```python
{
  "mpc_version": "1.0",
  "request_id": "uuid-v4",
  "idempotency_key": "optional-key",
  "timestamp": "2025-11-14T12:34:56Z",

  "source": {
    "application_id": "app-order-service",
    "environment": "prod",
    "version": "1.2.3"
  },

  "type": "process_request",
  "payload_schema": "llm.request.v1",
  "payload": {
    "model": "gpt-4",
    "prompt": "Analyze this security log",
    "max_tokens": 1000
  },

  "config": {
    "sensitivity": "internal",
    "processing_hint": "auto",
    "return_route": "sync",
    "timeout_ms": 30000,
    "enable_pii_detection": true,
    "enable_injection_detection": true
  },

  "auth": {
    "token": "jwt-bearer-token",
    "signature": "hmac-sha256-signature"
  }
}
```

### Response Schema

```python
{
  "mpc_version": "1.0",
  "request_id": "uuid-v4",
  "response_id": "uuid-v4",
  "timestamp": "2025-11-14T12:34:57Z",

  "status": "ok",  # ok | error | queued | processing

  "result": {
    "response": "Analysis complete...",
    "tokens": 156
  },

  "processing": {
    "backend": "openai:gpt-4",
    "latency_ms": 1234.5,
    "cost_usd": 0.0023,
    "confidence": 0.95,
    "fallback_used": false
  },

  "security_flags": {
    "has_pii": false,
    "injection_detected": false
  }
}
```

### Poziomy Wra≈ºliwo≈õci (Sensitivity)

| Poziom | Opis | Dozwolone Backendy |
|--------|------|-------------------|
| `public` | Dane publiczne | Wszystkie |
| `internal` | Dane wewnƒôtrzne | Wszystkie z wyjƒÖtkiem publicznych API |
| `sensitive` | Dane wra≈ºliwe | Tylko zaufane backendy |
| `pii` | Dane osobowe | Tylko on-prem / prywatne modele |
| `confidential` | Dane poufne | Tylko on-prem z szyfrowaniem |

---

## Bezpiecze≈Ñstwo i PII Handling

### Kluczowe Zasady

1. **Minimalizacja Danych** - przesy≈Çaj tylko to, co konieczne
2. **Tagowanie Wra≈ºliwo≈õci** - ka≈ºde payload ma `sensitivity`
3. **Encryption in Transit** - TLS 1.3 miƒôdzy wszystkimi hopami
4. **Short-lived Credentials** - JWT z kr√≥tkim TTL (15 min)
5. **Key Management** - sekrety z KMS (nie hardcoded!)
6. **Redaction & Tokenization** - maskuj/tokenizuj PII przed wys≈Çaniem
7. **PII-aware Routing** - dane z PII tylko do zatwierdzonych backend√≥w
8. **Data Retention** - automatyczne usuwanie po TTL
9. **Audit Logs** - structured logs bez PII w payloadach
10. **Least Privilege** - RBAC/ABAC dla ka≈ºdego zapytania

### PII Detection

```python
from security.pii_handler import PIIDetector

detector = PIIDetector()
result = detector.detect("My email is john@example.com and phone is 555-1234")

print(result.has_pii)  # True
print(result.pii_types)  # [PIIType.EMAIL, PIIType.PHONE]
print(result.matches)  # [PIIMatch(...), PIIMatch(...)]
```

### PII Redaction

```python
from security.pii_handler import PIIRedactor

# Strategia: REDACT | MASK | HASH | TOKENIZE
redactor = PIIRedactor(strategy="TOKENIZE")

text = "Contact me at john@example.com"
redacted, result = redactor.redact(text)

print(redacted)  # "Contact me at TOKEN_abc123def456"

# Odwr√≥cenie tokenizacji
original = redactor.detokenize(redacted)
print(original)  # "Contact me at john@example.com"
```

### PII-aware Routing

```python
from security.pii_handler import PIIRouter

router = PIIRouter(config={
    'routing_rules': {
        'no_pii': ['public_model', 'cloud_model'],
        'has_pii': ['private_model', 'on_prem_model'],
        'sensitive_pii': ['on_prem_model_encrypted']
    }
})

# Sprawd≈∫ dozwolone backendy
allowed = router.get_allowed_backends(
    text="Process my data",
    sensitivity="internal"
)

# Sprawd≈∫ czy zablokowaƒá
should_block, reason = router.should_block(
    text="My SSN is 123-45-6789",
    backend="openai:gpt-4"
)
# (True, "Backend not allowed for sensitive PII")
```

### Authentication & Authorization

```python
from security.auth import AccessControl, Permission, Role

# Inicjalizacja
access_control = AccessControl(
    jwt_secret="from-kms",
    hmac_secret="from-kms"
)

# Utworzenie tokenu
token = access_control.create_service_token(
    service_name="analytics-service",
    permissions=[Permission.READ, Permission.EXECUTE, Permission.PII_ACCESS]
)

# Uwierzytelnienie
principal = access_control.authenticate(token)

# Autoryzacja
is_authorized, reason = access_control.authorize(
    principal,
    action="process",
    resource_attributes={
        'sensitivity': 'pii',
        'estimated_cost': 0.5
    }
)
```

### Audit Logging

```python
from security.audit import AuditLogger, Outcome

audit = AuditLogger(log_file="audit.log")

# Logowanie zapytania (bez PII!)
audit.log_request(
    request_id="req-123",
    client_id=hash("user@example.com"),  # Zahashowane!
    action="process",
    sensitivity="internal",
    outcome=Outcome.SUCCESS
)

# Logowanie PII detection
audit.log_pii_detection(
    request_id="req-123",
    pii_types=["email", "phone"],
    action_taken="routed_to_private_model"
)

# Logowanie security violation
audit.log_security_violation(
    request_id="req-123",
    violation_type="prompt_injection",
    details={'pattern': 'ignore previous instructions'}
)
```

---

## Inteligentny Routing

### Strategie Routingu

#### 1. Capability Routing

Mapowanie zada≈Ñ do backend√≥w na podstawie mo≈ºliwo≈õci:

```python
from mpc_server.router import CapabilityRouter, CapabilityType

router = CapabilityRouter(backends)

# Pobierz backendy dla security scanning
backends = router.get_backends_for_capability(
    capability=CapabilityType.SECURITY_SCAN,
    sensitivity=SensitivityLevel.INTERNAL
)
# ‚Üí ['rules:pii-detector', 'rules:injection-detector']
```

#### 2. Confidence Cascade

Pr√≥buj tanich opcji, fallback do dro≈ºszych je≈õli niska pewno≈õƒá:

```python
from mpc_server.router import ConfidenceCascadeRouter

cascade = ConfidenceCascadeRouter(backends)

# Kolejno≈õƒá: od najta≈Ñszego do najdro≈ºszego
ordered = cascade.get_cascade_order(
    candidates=['gpt-4', 'gpt-3.5', 'llama2'],
    optimize_for="cost"
)
# ‚Üí ['llama2', 'gpt-3.5', 'gpt-4']

# ≈Åa≈Ñcuch fallback
fallbacks = cascade.get_fallback_chain(
    primary_backend='gpt-3.5',
    candidates=['gpt-4', 'gpt-3.5', 'llama2'],
    max_fallbacks=2
)
# ‚Üí ['gpt-4']
```

#### 3. Cost-Aware Routing

Wyb√≥r backendu z uwzglƒôdnieniem koszt√≥w i SLA:

```python
from mpc_server.router import CostAwareRouter

cost_router = CostAwareRouter(backends)

backend_id = cost_router.select_backend(
    candidates=['gpt-4', 'gpt-3.5', 'llama2'],
    max_cost=0.1,           # Max $0.10
    max_latency_ms=5000,    # Max 5s
    min_confidence=0.8,     # Min 80% confidence
    estimated_tokens=1000
)
# ‚Üí 'gpt-3.5' (najlepszy trade-off)
```

#### 4. Hybrid Pipeline

Kombinacja regu≈Ç + ML:

```
1. Rules (regex/heuristics) ‚Üí confidence < threshold?
2. Small Model (cheap/fast) ‚Üí confidence < threshold?
3. Large Model (expensive/slow) ‚Üí final answer
```

### IntelligentRouter - Kompletny System

```python
from mpc_server.router import IntelligentRouter, get_default_backends

router = IntelligentRouter(get_default_backends())

decision = router.route(
    capability=CapabilityType.TEXT_GENERATION,
    sensitivity=SensitivityLevel.INTERNAL,
    processing_hint=ProcessingHint.AUTO,
    max_cost=1.0,
    max_latency_ms=5000,
    estimated_tokens=1000,
    use_cascade=True
)

print(f"Backend: {decision.backend_id}")
print(f"Estimated cost: ${decision.estimated_cost:.4f}")
print(f"Estimated latency: {decision.estimated_latency_ms}ms")
print(f"Fallbacks: {decision.fallback_backends}")
```

### Konfiguracja Backend√≥w

```python
from mpc_server.router import Backend, BackendType, CapabilityType, SensitivityLevel

backends = [
    Backend(
        id="openai:gpt-4",
        type=BackendType.LLM_LARGE,
        capabilities=[
            CapabilityType.TEXT_GENERATION,
            CapabilityType.ANALYSIS,
            CapabilityType.CODE_GENERATION,
        ],
        cost_per_1k_tokens=0.03,
        avg_latency_ms=2000,
        max_tokens=8192,
        confidence_threshold=0.9,
        pii_allowed=False,
        sensitivity_allowed=[SensitivityLevel.PUBLIC, SensitivityLevel.INTERNAL]
    ),

    Backend(
        id="ollama:llama2",
        type=BackendType.LLM_PRIVATE,
        capabilities=[
            CapabilityType.TEXT_GENERATION,
            CapabilityType.SUMMARIZATION,
        ],
        cost_per_1k_tokens=0.0,  # Free (local)
        avg_latency_ms=3000,
        max_tokens=2048,
        confidence_threshold=0.7,
        pii_allowed=True,
        sensitivity_allowed=[
            SensitivityLevel.PUBLIC,
            SensitivityLevel.INTERNAL,
            SensitivityLevel.SENSITIVE,
            SensitivityLevel.PII,
        ]
    ),
]
```

---

## Przyk≈Çady U≈ºycia

### Przyk≈Çad 1: Podstawowe U≈ºycie

```python
import asyncio
from application.client import SimpleMPCClient

async def main():
    client = SimpleMPCClient(auth_token="token")

    response = await client.ask("What is API security?")
    print(response)

asyncio.run(main())
```

### Przyk≈Çad 2: PII Handling

```python
from application.client import MPCClient
from schemas.contracts import SensitivityLevel

client = MPCClient(auth_token="token")

# Zapytanie z PII automatycznie wykryte i zaroutowane do prywatnego modelu
result = await client.process(
    prompt="My email is john@example.com. Help with my account.",
    sensitivity=SensitivityLevel.PII,
    enable_pii_detection=True
)

print(f"Backend used: {result['backend']}")  # ‚Üí 'ollama:llama2' (private)
```

### Przyk≈Çad 3: Cost Optimization

```python
from schemas.contracts import ProcessingHint

# Proste zapytania ‚Üí regu≈Çy (darmowe)
simple_result = await client.process(
    prompt="Classify: ERROR message",
    processing_hint=ProcessingHint.RULE_ENGINE
)
print(f"Cost: ${simple_result['cost']:.4f}")  # ‚Üí $0.0000

# Z≈Ço≈ºone zapytania ‚Üí LLM (p≈Çatne)
complex_result = await client.process(
    prompt="Analyze architecture and provide recommendations",
    processing_hint=ProcessingHint.AUTO
)
print(f"Cost: ${complex_result['cost']:.4f}")  # ‚Üí $0.0234
```

### Przyk≈Çad 4: Confidence Cascade

```python
# Hybrid: pr√≥buje regu≈Ç, fallback do LLM je≈õli niska pewno≈õƒá
result = await client.process(
    prompt="What does 'the spirit is willing but the flesh is weak' mean?",
    processing_hint=ProcessingHint.HYBRID
)

print(f"Strategy: {result['strategy']}")  # ‚Üí 'llm_fallback'
print(f"Confidence: {result['confidence']}")  # ‚Üí 0.95
```

### Przyk≈Çad 5: Batch Processing

```python
prompts = [
    "Classify: Hello there",
    "Classify: Error 404",
    "Classify: Security threat detected",
]

results = await client.batch_process(
    prompts,
    processing_hint=ProcessingHint.RULE_ENGINE
)

for prompt, result in zip(prompts, results):
    print(f"{prompt} ‚Üí {result['response']}")
```

### Pe≈Çny Przyk≈Çad

Uruchom kompletne przyk≈Çady:

```bash
cd poc
python -m application.example_usage
```

---

## Deployment

### Lokalne Uruchomienie

```bash
# Instalacja zale≈ºno≈õci
pip install -r requirements.txt

# Uruchomienie Ollama (opcjonalnie)
docker-compose up -d ollama

# Inicjalizacja backend√≥w
python -c "from processing.backends import initialize_default_backends; initialize_default_backends()"

# Uruchomienie przyk≈Çad√≥w
python -m application.example_usage
```

### Konfiguracja Produkcyjna

```python
from mpc_server.server import MPCServer, MPCServerConfig

config = MPCServerConfig(
    jwt_secret=os.getenv("JWT_SECRET"),  # Z KMS!
    hmac_secret=os.getenv("HMAC_SECRET"),  # Z KMS!
    enable_pii_detection=True,
    enable_audit=True,
    audit_log_file="/var/log/mpc_audit.log",
    max_request_size_bytes=5 * 1024 * 1024,  # 5MB
    request_timeout_ms=60000
)

server = MPCServer(**config.__dict__)
```

---

## Roadmap

### ‚úÖ Zaimplementowane (v1.0)

- [x] Architektura 3-warstwowa
- [x] JSON-RPC kontrakt z wersjonowaniem
- [x] MPC Server z walidacjƒÖ i routingiem
- [x] PII detection i redaction
- [x] Authentication & Authorization (JWT, RBAC/ABAC)
- [x] Intelligent routing (capability, cascade, cost-aware)
- [x] Hybrid backends (rules + LLM)
- [x] Audit logging
- [x] Application layer client
- [x] Processing backends (OpenAI, Ollama, Rules, Hybrid)

### üöß Nastƒôpne Kroki (v2.0)

- [ ] HTTP/gRPC API dla MPC Server
- [ ] Async processing z webhookami
- [ ] Message broker integration (Kafka/RabbitMQ)
- [ ] Distributed tracing (OpenTelemetry)
- [ ] Metrics & monitoring (Prometheus/Grafana)
- [ ] Rate limiting i quotas
- [ ] Cache layer (Redis)
- [ ] Multi-tenancy support

### üîÆ Przysz≈Ço≈õƒá (v3.0+)

- [ ] ML-based PII detection (zamiast regex)
- [ ] Predictive routing (ML-based backend selection)
- [ ] Auto-scaling based on load
- [ ] Kubernetes deployment
- [ ] SaaS offering

---

## Podsumowanie

Architektura 3-warstwowa AI SIEM zapewnia:

‚úÖ **Separation of Concerns** - ka≈ºda warstwa ma jasno okre≈õlone odpowiedzialno≈õci
‚úÖ **Security by Design** - PII handling, auth, audit na ka≈ºdym poziomie
‚úÖ **Scalability** - niezale≈ºne skalowanie warstw
‚úÖ **Flexibility** - ≈Çatwa wymiana backend√≥w i modeli
‚úÖ **Cost Optimization** - inteligentny routing minimalizuje koszty
‚úÖ **Compliance** - audit logs i data retention policies

**Kluczowe Zasady:**

1. **Application Layer** = klient (zbiera kontekst, buduje zapytania)
2. **Collection Layer (MPC)** = po≈õrednik (walidacja, routing, kontrola)
3. **Processing Layer** = silnik (faktyczne przetwarzanie)

**Dodatkowe Dokumenty:**

- [FLOW_DIAGRAM.md](FLOW_DIAGRAM.md) - Szczeg√≥≈Çowy diagram przep≈Çywu
- [README.md](README.md) - PrzeglƒÖd projektu
- [poc/README.md](poc/README.md) - Dokumentacja POC
